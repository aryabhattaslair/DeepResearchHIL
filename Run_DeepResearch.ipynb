{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c699f542-0931-4e32-afa6-eea66b465363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid \n",
    "import os, getpass\n",
    "\n",
    "from langgraph.types import Command\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from open_deep_research.graph import builder\n",
    "import asyncio\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf2f87ee-6971-4360-9f95-2b9c6f020412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define report structure template and configure the research workflow\n",
    "# This sets parameters for models, search tools, and report organization\n",
    "REPORT_STRUCTURE = \"\"\"Use this structure to create a report on the user-provided topic:\n",
    "\n",
    "    1. Introduction (no research needed)\n",
    "    - Brief overview of the topic area\n",
    "\n",
    "    2. Main Body Sections:\n",
    "    - Each section should focus on a sub-topic of the user-provided topic\n",
    "\n",
    "    3. Conclusion\n",
    "    - Aim for 1 structural element (either a list of table) that distills the main body sections \n",
    "    - Provide a concise summary of the report\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce71b4ca-30eb-4456-b38a-d31d8f5946fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def Run_DR(thread):\n",
    "    memory = MemorySaver()\n",
    "    graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "    # Define research topic about Model Context Protocol\n",
    "    topic = \"Tell me about inference time compute scaling and how that improves thinking models.\"\n",
    "\n",
    "    # Run the graph workflow until first interruption (waiting for user feedback)\n",
    "    # async for event in graph.astream({\"topic\":topic,}, thread, stream_mode=\"updates\"):\n",
    "    #    if '__interrupt__' in event:\n",
    "    #        interrupt_value = event['__interrupt__'][0].value\n",
    "    #        print(interrupt_value)\n",
    "\n",
    "    # Provide specific feedback to focus and refine the report structure\n",
    "    # async for event in graph.astream(Command(resume=\"Looks great! \"), thread, stream_mode=\"updates\"):\n",
    "    #    if '__interrupt__' in event:\n",
    "    #        interrupt_value = event['__interrupt__'][0].value\n",
    "    #        print(interrupt_value)\n",
    "\n",
    "    # Approve the final plan and execute the report generation\n",
    "    # This triggers the research and writing phases for all sections\n",
    "\n",
    "    # The system will now:\n",
    "    # 1. Research each section topic\n",
    "    # 2. Generate content with citations\n",
    "    # 3. Create introduction and conclusion\n",
    "    # 4. Compile the final report\n",
    "    async for event in graph.astream({\"topic\":topic,}, thread, stream_mode=\"updates\"):\n",
    "        print(event)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    final_state = graph.get_state(thread)\n",
    "    report = final_state.values.get('final_report')\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30972b9-4b9b-4665-ad37-97bcc5549e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generate_report_plan': {'sections': [Section(name='Introduction to Inference-Time Compute Scaling', description='Introduce inference-time compute scaling and its significance for improving LLM reasoning.', research=False, content=''), Section(name='Defining Inference-Time Compute Scaling', description='Define inference-time compute scaling and explain how it differs from training-time scaling. Detail the core mechanisms, such as prompting strategies and search algorithms.', research=True, content=''), Section(name='Techniques for Inference-Time Compute Scaling', description='Explore specific techniques used in inference-time compute scaling, including chain-of-thought prompting, self-reflection, and ensemble methods. Provide examples of how these techniques are implemented.', research=True, content=''), Section(name='Impact on LLM Performance', description='Discuss the impact of inference-time compute scaling on the performance of LLMs, including improvements in accuracy, reasoning capabilities, and handling of complex tasks. Include examples of performance gains.', research=True, content=''), Section(name='Trade-offs and Limitations', description='Analyze the trade-offs associated with inference-time compute scaling, such as increased computational costs, latency, and potential limitations. Discuss the cost-benefit analysis.', research=True, content=''), Section(name='Conclusion', description=\"Summarize the key findings and provide a concise overview of the report's main points. Include a table or list that distills the main body sections.\", research=False, content='')]}}\n",
      "\n",
      "\n",
      "{'human_feedback': None}\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m      5\u001b[39m thread = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(uuid.uuid4()),\n\u001b[32m      6\u001b[39m                        \u001b[33m\"\u001b[39m\u001b[33msearch_api\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtavily\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m                        \u001b[33m\"\u001b[39m\u001b[33mplanner_provider\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mgoogle\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m                        \u001b[33m\"\u001b[39m\u001b[33mreport_structure\u001b[39m\u001b[33m\"\u001b[39m: REPORT_STRUCTURE,\n\u001b[32m     15\u001b[39m                        }}\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Submit feedback on the report plan\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# The system will continue execution with the updated requirements\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m Run_DR(thread)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mRun_DR\u001b[39m\u001b[34m(thread)\u001b[39m\n\u001b[32m      6\u001b[39m topic = \u001b[33m\"\u001b[39m\u001b[33mTell me about inference time compute scaling and how that improves thinking models.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Run the graph workflow until first interruption (waiting for user feedback)\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# async for event in graph.astream({\"topic\":topic,}, thread, stream_mode=\"updates\"):\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#    if '__interrupt__' in event:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# 3. Create introduction and conclusion\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# 4. Compile the final report\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m graph.astream({\u001b[33m\"\u001b[39m\u001b[33mtopic\u001b[39m\u001b[33m\"\u001b[39m:topic,}, thread, stream_mode=\u001b[33m\"\u001b[39m\u001b[33mupdates\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mprint\u001b[39m(event)\n\u001b[32m     30\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Code/flowvenv/lib/python3.12/site-packages/langgraph/pregel/main.py:2937\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2935\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.amatch_cached_writes():\n\u001b[32m   2936\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2937\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2938\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2939\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2940\u001b[39m     get_waiter=get_waiter,\n\u001b[32m   2941\u001b[39m     schedule_task=loop.aaccept_push,\n\u001b[32m   2942\u001b[39m ):\n\u001b[32m   2943\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2944\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m _output(\n\u001b[32m   2945\u001b[39m         stream_mode,\n\u001b[32m   2946\u001b[39m         print_mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2949\u001b[39m         asyncio.QueueEmpty,\n\u001b[32m   2950\u001b[39m     ):\n\u001b[32m   2951\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Code/flowvenv/lib/python3.12/site-packages/langgraph/pregel/_runner.py:401\u001b[39m, in \u001b[36mPregelRunner.atick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m.\u001b[49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout_exc_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTimeoutError\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpanic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    407\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tb := exc.__traceback__:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Code/flowvenv/lib/python3.12/site-packages/langgraph/pregel/_runner.py:511\u001b[39m, in \u001b[36m_panic_or_proceed\u001b[39m\u001b[34m(futs, timeout_exc_cls, panic)\u001b[39m\n\u001b[32m    509\u001b[39m                 interrupts.append(exc)\n\u001b[32m    510\u001b[39m             \u001b[38;5;28;01melif\u001b[39;00m fut \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SKIP_RERAISE_SET:\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    512\u001b[39m \u001b[38;5;66;03m# raise combined interrupts\u001b[39;00m\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupts:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Code/flowvenv/lib/python3.12/site-packages/langgraph/pregel/_retry.py:137\u001b[39m, in \u001b[36marun_with_retry\u001b[39m\u001b[34m(task, retry_policy, stream, match_cached_writes, configurable)\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task.proc.ainvoke(task.input, config)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    139\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Code/flowvenv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:695\u001b[39m, in \u001b[36mRunnableSeq.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    693\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    694\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(\n\u001b[32m    696\u001b[39m             step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs), context=context\n\u001b[32m    697\u001b[39m         )\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Code/flowvenv/lib/python3.12/site-packages/langgraph/pregel/main.py:3099\u001b[39m, in \u001b[36mPregel.ainvoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   3096\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3097\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3099\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.astream(\n\u001b[32m   3100\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   3101\u001b[39m     config,\n\u001b[32m   3102\u001b[39m     context=context,\n\u001b[32m   3103\u001b[39m     stream_mode=[\u001b[33m\"\u001b[39m\u001b[33mupdates\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   3104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[32m   3106\u001b[39m     print_mode=print_mode,\n\u001b[32m   3107\u001b[39m     output_keys=output_keys,\n\u001b[32m   3108\u001b[39m     interrupt_before=interrupt_before,\n\u001b[32m   3109\u001b[39m     interrupt_after=interrupt_after,\n\u001b[32m   3110\u001b[39m     **kwargs,\n\u001b[32m   3111\u001b[39m ):\n\u001b[32m   3112\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   3113\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Code/flowvenv/lib/python3.12/site-packages/langgraph/pregel/main.py:2937\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2935\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.amatch_cached_writes():\n\u001b[32m   2936\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2937\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2938\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2939\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2940\u001b[39m     get_waiter=get_waiter,\n\u001b[32m   2941\u001b[39m     schedule_task=loop.aaccept_push,\n\u001b[32m   2942\u001b[39m ):\n\u001b[32m   2943\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2944\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m _output(\n\u001b[32m   2945\u001b[39m         stream_mode,\n\u001b[32m   2946\u001b[39m         print_mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2949\u001b[39m         asyncio.QueueEmpty,\n\u001b[32m   2950\u001b[39m     ):\n\u001b[32m   2951\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Code/flowvenv/lib/python3.12/site-packages/langgraph/pregel/_runner.py:295\u001b[39m, in \u001b[36mPregelRunner.atick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    293\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[32m    296\u001b[39m         t,\n\u001b[32m    297\u001b[39m         retry_policy,\n\u001b[32m    298\u001b[39m         stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    299\u001b[39m         configurable={\n\u001b[32m    300\u001b[39m             CONFIG_KEY_CALL: partial(\n\u001b[32m    301\u001b[39m                 _acall,\n\u001b[32m    302\u001b[39m                 weakref.ref(t),\n\u001b[32m    303\u001b[39m                 stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    304\u001b[39m                 retry_policy=retry_policy,\n\u001b[32m    305\u001b[39m                 futures=weakref.ref(futures),\n\u001b[32m    306\u001b[39m                 schedule_task=schedule_task,\n\u001b[32m    307\u001b[39m                 submit=\u001b[38;5;28mself\u001b[39m.submit,\n\u001b[32m    308\u001b[39m                 loop=loop,\n\u001b[32m    309\u001b[39m             ),\n\u001b[32m    310\u001b[39m         },\n\u001b[32m    311\u001b[39m     )\n\u001b[32m    312\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Code/flowvenv/lib/python3.12/site-packages/langgraph/pregel/_retry.py:137\u001b[39m, in \u001b[36marun_with_retry\u001b[39m\u001b[34m(task, retry_policy, stream, match_cached_writes, configurable)\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task.proc.ainvoke(task.input, config)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    139\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Code/flowvenv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:695\u001b[39m, in \u001b[36mRunnableSeq.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    693\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    694\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(\n\u001b[32m    696\u001b[39m             step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs), context=context\n\u001b[32m    697\u001b[39m         )\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Code/flowvenv/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:463\u001b[39m, in \u001b[36mRunnableCallable.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    461\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m run_manager.on_chain_end(ret)\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     ret = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.afunc(*args, **kwargs)\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ret.ainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Development/Code/DeepResearchHIL/src/open_deep_research/graph.py:216\u001b[39m, in \u001b[36mread_pdf\u001b[39m\u001b[34m(state, config)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Read a PDF file and return its text content.\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    213\u001b[39m \u001b[33;03mstr: Text content of the PDF.\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPyPDF2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PdfReader\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m reader = PdfReader(\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpath\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m    217\u001b[39m text = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m reader.pages:\n",
      "\u001b[31mKeyError\u001b[39m: 'path'",
      "During task with name 'read_pdf' and id 'eb131e80-19ad-cb6a-33e2-0087795fdd24'",
      "During task with name 'build_section_with_pdf_research' and id 'e7077c85-7ad2-9b96-9110-a1b3cb858f2f'"
     ]
    }
   ],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = \"Google API Key\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"Tavily API Key\"\n",
    "\n",
    "# Configuration option 1: Claude 3.7 Sonnet for planning with perplexity search\n",
    "thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4()),\n",
    "                       \"search_api\": \"tavily\",\n",
    "                       \"planner_provider\": \"google\",\n",
    "                       \"planner_model\": \"gemini-2.0-flash-lite\",\n",
    "                       # \"planner_model_kwargs\": {\"temperature\":0.8}, # if set custom parameters\n",
    "                       \"writer_provider\": \"google\",\n",
    "                       \"writer_model\": \"gemini-2.0-flash-lite\",\n",
    "                       # \"writer_model_kwargs\": {\"temperature\":0.8}, # if set custom parameters\n",
    "                       \"max_search_depth\": 2,\n",
    "                       \"report_structure\": REPORT_STRUCTURE,\n",
    "                       }}\n",
    "\n",
    "# Submit feedback on the report plan\n",
    "# The system will continue execution with the updated requirements\n",
    "await Run_DR(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390f538c-54a9-4c79-9e91-c4619be02991",
   "metadata": {},
   "outputs": [],
   "source": [
    "true"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
